import pennylane as qml
import torch
import torch.nn as nn

# PQWGAN_QC class: A hybrid quantum-classical WGAN architecture with quantum generator and critic
class PQWGAN_QC():
    def __init__(self, image_size, channels, n_generators, n_gen_qubits, n_ancillas, n_gen_layers, patch_shape, n_critic_qubits, n_critic_layers):
        # Initialize parameters for the PQWGAN_QC model
        # `image_size`: Dimension of images (assumes square)
        # `channels`: Number of channels in the images (e.g., 1 for grayscale)
        # `n_generators`: Number of sub-generators used in the Quantum Generator
        # `n_gen_qubits`: Number of qubits per sub-generator
        # `n_ancillas`: Ancilla qubits for post-processing in generator
        # `n_gen_layers`: Number of layers in the generator
        # `patch_shape`: Shape of patches generated by each sub-generator
        # `n_critic_qubits`: Number of qubits in the Quantum Critic
        # `n_critic_layers`: Number of layers in the Quantum Critic
        
        self.image_shape = (channels, image_size, image_size)
        self.critic = self.QuantumCritic(n_critic_qubits, n_critic_layers)  # Initialize the Quantum Critic
        self.generator = self.QuantumGenerator(n_generators, n_gen_qubits, n_ancillas, n_gen_layers, self.image_shape, patch_shape)  # Initialize the Quantum Generator

    # QuantumCritic class: A quantum neural network for discriminating real from fake images
    class QuantumCritic(nn.Module):
        def __init__(self, n_qubits, n_layers):
            super().__init__()
            # Initialize parameters for the Quantum Critic
            # `n_qubits`: Number of qubits used in the circuit
            # `n_layers`: Number of layers of entangling operations
            
            self.n_qubits = n_qubits
            # Create a QNode using a Pennylane device with the specified number of qubits
            self.qnode = qml.QNode(self.circuit, qml.device("default.qubit", wires=n_qubits))
            # Define weight shapes for the quantum circuit
            self.weight_shapes = {"weights": qml.StronglyEntanglingLayers.shape(n_layers=n_layers, n_wires=n_qubits)}
            # Create a quantum layer using TorchLayer to integrate with PyTorch
            self.qlayer = qml.qnn.TorchLayer(self.qnode, self.weight_shapes)

        # Define the quantum circuit for the critic
        def circuit(self, inputs, weights):
            assert inputs.shape[0] <= 2 ** self.n_qubits, "Need more qubits to encode vector"
            # Embed input data into the quantum state using amplitude encoding
            qml.AmplitudeEmbedding(inputs, wires=range(self.n_qubits), pad_with=0., normalize=True)
            # Apply a series of strongly entangling layers with the given weights
            qml.StronglyEntanglingLayers(weights, wires=range(self.n_qubits))
            # Return the expectation value of the PauliZ operator on the first qubit
            return qml.expval(qml.PauliZ(wires=0))

        # Forward pass for the Quantum Critic
        def forward(self, x):
            # Flatten the input tensor
            x = x.view(x.shape[0], -1)
            # Pass the input through the quantum layer
            x = self.qlayer(x)
            # Prevent extreme values by adjusting the output
            sign = torch.sign(x)
            x = torch.abs(x) * torch.pi/2 - 0.001  # Avoid infinite values during tan calculation
            x *= sign
            print(torch.tan(x))  # Debugging output
            # Return the tan of the adjusted output
            return torch.tan(x)

    # QuantumGenerator class: A quantum neural network for generating images
    class QuantumGenerator(nn.Module):
        def __init__(self, n_generators, n_qubits, n_ancillas, n_layers, image_shape, patch_shape):
            super().__init__()
            # Initialize parameters for the Quantum Generator
            # `n_generators`: Number of sub-generators
            # `n_qubits`: Number of qubits in the circuit
            # `n_ancillas`: Ancilla qubits for post-processing
            # `n_layers`: Number of layers in the circuit
            # `image_shape`: Shape of the generated images
            # `patch_shape`: Shape of patches produced by each sub-generator

            self.n_generators = n_generators
            self.n_qubits = n_qubits
            self.n_ancillas = n_ancillas
            self.n_layers = n_layers
            self.q_device = qml.device("default.qubit", wires=n_qubits)  # Define a Pennylane quantum device
            # Initialize quantum parameters for each sub-generator
            self.params = nn.ParameterList([nn.Parameter(torch.rand(n_layers, n_qubits, 3), requires_grad=True) for _ in range(n_generators)])
            # Create a QNode for the generator circuit
            self.qnode = qml.QNode(self.circuit, self.q_device, interface="torch")

            self.image_shape = image_shape
            self.patch_shape = patch_shape

        # Forward pass for the Quantum Generator
        def forward(self, x):
            # Determine if a special patch shape is used
            special_shape = bool(self.patch_shape[0]) and bool(self.patch_shape[1])
            patch_size = 2 ** (self.n_qubits - self.n_ancillas)  # Size of each generated patch
            image_pixels = self.image_shape[2] ** 2  # Total number of pixels in the image
            pixels_per_patch = image_pixels // self.n_generators  # Number of pixels per patch
            if special_shape and self.patch_shape[0] * self.patch_shape[1] != pixels_per_patch:
                raise ValueError("patch shape and patch size don't match!")
            
            # Initialize a tensor to store generated images
            output_images = torch.Tensor(x.size(0), 0)

            # Loop through each sub-generator's parameters
            for sub_generator_param in self.params:
                patches = torch.Tensor(0, pixels_per_patch)
                for item in x:
                    # Generate a patch using the latent vector and quantum circuit
                    sub_generator_out = self.partial_trace_and_postprocess(item, sub_generator_param).float().unsqueeze(0)
                    # Trim if patch size exceeds the required pixels per patch
                    if pixels_per_patch < patch_size:
                        sub_generator_out = sub_generator_out[:, :pixels_per_patch]
                    patches = torch.cat((patches, sub_generator_out))
                # Concatenate patches to form the final output image
                output_images = torch.cat((output_images, patches), 1)

            # Construct the final output image with the special patch shape if required
            if special_shape:
                final_out = torch.zeros(x.size(0), *self.image_shape)
                for i, img in enumerate(output_images):
                    for patches_done, j in enumerate(range(0, img.shape[0], pixels_per_patch)):
                        patch = torch.reshape(img[j:j+pixels_per_patch], self.patch_shape)
                        starting_h = ((patches_done * self.patch_shape[1]) // self.image_shape[2]) * self.patch_shape[0]
                        starting_w = (patches_done * self.patch_shape[1]) % self.image_shape[2]
                        # Place the patch in the appropriate location in the output image
                        final_out[i, 0, starting_h:starting_h+self.patch_shape[0], starting_w:starting_w+self.patch_shape[1]] = patch
            else:
                # Reshape the output to match the image shape
                final_out = output_images.view(output_images.shape[0], *self.image_shape)
            return final_out

        # Define the quantum circuit for the generator
        def circuit(self, latent_vector, weights):
            # Apply rotations to each qubit based on the latent vector
            for i in range(self.n_qubits):
                qml.RY(latent_vector[i], wires=i)
            
            # Apply layers of rotation and entanglement
            for i in range(self.n_layers):
                for j in range(self.n_qubits):
                    qml.Rot(*weights[i][j], wires=j)  # Apply rotational gates

                # Apply CNOT entanglement between adjacent qubits
                for j in range(self.n_qubits - 1):
                    qml.CNOT(wires=[j, j + 1])
            
            # Return the probability distribution over the quantum states
            return qml.probs(wires=list(range(self.n_qubits)))

        # Perform partial trace and normalize the output to generate image patches
        def partial_trace_and_postprocess(self, latent_vector, weights):
            # Get the probability distribution from the quantum circuit
            probs = self.qnode(latent_vector, weights)
            # Focus on the subspace where the ancilla is in the |0> state
            probs_given_ancilla_0 = probs[:2**(self.n_qubits - self.n_ancillas)]
            # Normalize the probabilities to ensure they sum to 1
            post_measurement_probs = probs_given_ancilla_0 / torch.sum(probs)
            
            # Normalize values between [-1, 1] for image pixel values
            post_processed_patch = ((post_measurement_probs / torch.max(post_measurement_probs)) - 0.5) * 2
            return post_processed_patch

# Testing the Quantum Critic by visualizing the quantum circuit
if __name__ == "__main__":
    # Initialize a sample Quantum Critic with test parameters
    gen = PQWGAN_QC(image_size=16, channels=1, n_generators=16, n_gen_qubits=5, n_ancillas=1, n_gen_layers=1, n_critic_qubits=5, n_critic_layers=1).critic
    # Visualize the quantum circuit with sample inputs
    print(qml.draw(gen.qnode, expansion_strategy="device")(torch.rand(32), torch.rand(1,5,3)))
